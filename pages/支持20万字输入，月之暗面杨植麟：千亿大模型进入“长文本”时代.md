title:: 支持20万字输入，月之暗面杨植麟：千亿大模型进入“长文本”时代
author:: [[甲子光年]]
url:: https://36kr.com/p/2468455352145798
tags:: #[[AI]] #[[Readwise]]  
![](https://img.36krcdn.com/hsossms/20231010/v2_6776c88910ff45f784054a84bd52dcd0@5888275_oswg154325oswg1053oswg495_img_png?x-oss-process=image/resize,m_mfit,w_600,h_400,limit_0/crop,w_600,h_400,g_center)

- > 对于长文本技术的开发，市场上出现了不同的技术路线。但在杨植麟看来，这些路线几乎都是在牺牲一部分性能前提下的“捷径”。 杨植麟将其总结为三类：
  
  “金鱼”模型，容易“健忘”。通过滑动窗口等方式主动抛弃上文，只保留对最新输入的注意力机制。模型无法对全文进行完整理解，无法处理跨文档的比较和长文本的综合理解。例如，无法从一篇10万字的用户访谈录音转写中提取最有价值的10个观点。
  
  “蜜蜂”模型，只关注局部，忽略整体。通过对上下文的降采样或者RAG（检索增强的生成），只保留对部分输入的注意力机制。模型同样无法对全文进行完整理解。例如，无法从50个简历中对候选人的画像进行归纳和总结。
  
  “蝌蚪”模型，模型能力尚未发育完整。通过减少参数量（例如减少到百亿参数）来提升上下文长度，这种方法会降低模型本身的能力，虽然能支持更长上下文，但是大量任务无法胜任。
  
  杨植麟认为，简单的捷径无法达到理想的产品化效果。因此，月之暗面的技术路线，就是不走捷径，踏实地解决算法与工程的双重挑战，在算力、存储、带宽等技术层面做了极致的优化。 ([View Highlight](https://read.readwise.io/read/01hqz3c88s3y0bmnm3ets24f05))